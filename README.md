# ğŸ“Š PredicciÃ³n de AprobaciÃ³n de Curso de MatemÃ¡ticas mediante Redes Neuronales

## ğŸ‘¥ Equipo de Trabajo
- **Juan Esteban Ortiz** - 2410227-3743
- **Juan David Olaya** - 202410206-3743
- **Pablo Esteban Becerra** - 202243506-3743
- **Fernando Cardona Giraldo** - 202241381-3743
- **Sara Yineth Suarez Reyes** - 202241923-3743

---

## ğŸ“– DescripciÃ³n del Proyecto

Este proyecto implementa modelos de **redes neuronales multicapa (MLP)** para predecir si un estudiante aprobarÃ¡ un curso de matemÃ¡ticas basÃ¡ndose en sus caracterÃ­sticas demogrÃ¡ficas, familiares y hÃ¡bitos de estudio.

### ğŸ¯ Objetivo
Desarrollar y comparar diferentes arquitecturas de redes neuronales para clasificar estudiantes en dos categorÃ­as:
- **Aprueba** (approved = 1)
- **No aprueba** (approved = 0)

---

## ğŸ“ Estructura del Proyecto

```
ActividadML/
â”‚
â”œâ”€â”€ notebook1.ipynb                    # Actividad 1: Redes Neuronales
â”œâ”€â”€ notebook2.ipynb                    # Actividad 2: Ãrboles de DecisiÃ³n
â”œâ”€â”€ student_performance.csv            # Dataset de estudiantes
â”œâ”€â”€ Informe Machine learning.pdf       # Informe completo del proyecto
â””â”€â”€ README.md                          # Este archivo
```

---

## ğŸ“Š Dataset

**Archivo:** `student_performance.csv`

### CaracterÃ­sticas del Dataset:
- **Total de registros:** 1,044 estudiantes
- **Atributos totales:** 17 variables
- **Variable objetivo:** `approved` (binaria: 0 o 1)

### Atributos NumÃ©ricos (9):
1. `age` - Edad del estudiante
2. `Medu` - EducaciÃ³n de la madre (0-4)
3. `Fedu` - EducaciÃ³n del padre (0-4)
4. `traveltime` - Tiempo de viaje al colegio
5. `studytime` - Tiempo de estudio semanal
6. `failures` - NÃºmero de materias reprobadas
7. `goout` - Frecuencia de salidas
8. `Walc` - Consumo de alcohol fin de semana
9. `health` - Estado de salud (1-5)

### Atributos CategÃ³ricos (7):
1. `sex` - Sexo (M/F)
2. `famsize` - TamaÃ±o de familia
3. `Pstatus` - Estado de convivencia de los padres
4. `Mjob` - OcupaciÃ³n de la madre
5. `Fjob` - OcupaciÃ³n del padre
6. `internet` - Acceso a internet (yes/no)
7. `romantic` - En relaciÃ³n romÃ¡ntica (yes/no)

---

## ğŸ› ï¸ TecnologÃ­as y LibrerÃ­as

```python
- Python 3.x
- scikit-learn      # Modelos de ML y preprocesamiento
- pandas            # ManipulaciÃ³n de datos
- numpy             # Operaciones numÃ©ricas
- matplotlib        # VisualizaciÃ³n
```

---

## ğŸ”„ Pipeline de Preprocesamiento

### 1. **Pipeline para Atributos NumÃ©ricos**
```python
num_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),    # ImputaciÃ³n de valores faltantes
    ("scaler", StandardScaler())                       # NormalizaciÃ³n (Î¼=0, Ïƒ=1)
])
```

### 2. **Pipeline para Atributos CategÃ³ricos**
```python
cat_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),  # ImputaciÃ³n con moda
    ("cat_encoder", OneHotEncoder(sparse_output=False))     # CodificaciÃ³n One-Hot
])
```

### 3. **Pipeline Completo**
```python
full_pipeline = ColumnTransformer([
    ("num", num_pipeline, num_attribs),
    ("cat", cat_pipeline, cat_attribs),
])
```

**Resultado:** 9 atributos numÃ©ricos + codificaciÃ³n categÃ³rica â†’ matriz de caracterÃ­sticas lista para entrenamiento

---

---

# ğŸ“˜ ACTIVIDAD 1: Redes Neuronales (notebook1.ipynb)

## ğŸ§  Modelos Implementados

Se entrenaron **5 modelos de redes neuronales** con diferentes configuraciones:

| Modelo | FunciÃ³n ActivaciÃ³n | Solver | Arquitectura | Learning Rate |
|--------|-------------------|--------|--------------|---------------|
| **Modelo 1** | ReLU | LBFGS | (10, 5) | - |
| **Modelo 2** | Identity | SGD | (5, 6, 7) | constant |
| **Modelo 3** | Tanh | Adam | (8, 3, 2, 6) | - |
| **Modelo 4** | Logistic | Adam | (20,) | - |
| **Modelo 5** | ReLU | Adam | (3, 5, 7, 9, 10) | - |

### ParÃ¡metros Comunes:
- **DivisiÃ³n de datos:** 80% entrenamiento / 20% prueba
- **MÃ©trica de evaluaciÃ³n:** Accuracy
- **Max iteraciones:** 1000

---

## ğŸ“ˆ Resultados

### Primera EjecuciÃ³n (sin learning_rate):
- **Mejor modelo:** Modelo 2
- **Accuracy:** 0.8182
- **ConfiguraciÃ³n:** activation='identity', solver='sgd', hidden_layer_sizes=(5,6,7)

### OptimizaciÃ³n con learning_rate:
| ConfiguraciÃ³n | Accuracy | ObservaciÃ³n |
|--------------|----------|-------------|
| `learning_rate='constant'` | **0.8278** | âœ… Mejor resultado |
| `learning_rate='adaptive'` | 0.8086 | âš ï¸ DisminuciÃ³n |
| `learning_rate='invscaling'` | 0.7273 | âŒ Peor resultado |

### ğŸ† ConclusiÃ³n Actividad 1:
El **Modelo 2 con learning_rate='constant'** logrÃ³ el mejor desempeÃ±o con **82.78% de accuracy**.

---

# ğŸŒ³ ACTIVIDAD 2: Ãrboles de DecisiÃ³n (notebook2.ipynb)

## ğŸ“‹ DescripciÃ³n

Esta actividad aplica **Ã¡rboles de decisiÃ³n** al mismo dataset de estudiantes, comparando diferentes configuraciones de hiperparÃ¡metros para optimizar el rendimiento del clasificador.

## ğŸ¯ Objetivo

Determinar los hiperparÃ¡metros Ã³ptimos para un Ã¡rbol de decisiÃ³n que prediga la aprobaciÃ³n del curso de matemÃ¡ticas, experimentando con:
- Diferentes profundidades del Ã¡rbol (`max_depth`)
- Criterios de impureza (`gini` vs `entropy`)
- NÃºmero mÃ­nimo de muestras para dividir (`min_samples_split`)

## ğŸŒ² Modelos de Ãrboles de DecisiÃ³n

### Experimento 1: VariaciÃ³n de max_depth con criterio Gini

| Modelo | max_depth | Criterio | Accuracy |
|--------|-----------|----------|----------|
| Modelo 1 | 2 | gini | ~0.74 |
| Modelo 2 | 4 | gini | **0.8373** |
| Modelo 3 | 6 | gini | ~0.81 |
| Modelo 4 | 8 | gini | ~0.80 |
| Modelo 5 | 10 | gini | ~0.78 |

### Experimento 2: VariaciÃ³n de max_depth con criterio Entropy

| Modelo | max_depth | Criterio | Accuracy |
|--------|-----------|----------|----------|
| Modelo 1 | 2 | entropy | ~0.74 |
| Modelo 2 | 4 | entropy | **0.8373** |
| Modelo 3 | 6 | entropy | ~0.81 |
| Modelo 4 | 8 | entropy | ~0.80 |
| Modelo 5 | 10 | entropy | ~0.78 |

### ğŸ” ObservaciÃ³n Importante:
Ambos criterios (`gini` y `entropy`) producen **resultados idÃ©nticos** con `max_depth=4`, logrando **83.73% de accuracy**. Esto indica que ambos mÃ©todos encuentran las mismas divisiones Ã³ptimas en el Ã¡rbol.

### Experimento 3: VariaciÃ³n de min_samples_split

Con los mejores hiperparÃ¡metros (`max_depth=4`, `criterion='gini'`):

| min_samples_split | Accuracy |
|-------------------|----------|
| 2 | 0.8373 |
| 10 | 0.8373 |
| 20 | 0.8373 |

**ConclusiÃ³n:** El parÃ¡metro `min_samples_split` **no afecta** el accuracy cuando `max_depth=4`, ya que la profundidad mÃ¡xima limita el crecimiento del Ã¡rbol antes de que este parÃ¡metro entre en acciÃ³n.

## ğŸ† ConfiguraciÃ³n Ã“ptima del Ãrbol

```python
DecisionTreeClassifier(
    max_depth=4,
    criterion='gini',  # o 'entropy' (mismo resultado)
    min_samples_split=2
)
```

**Accuracy alcanzado:** **83.73%**

## ğŸ“Š ComparaciÃ³n: Redes Neuronales vs Ãrboles de DecisiÃ³n

| TÃ©cnica | Mejor Accuracy | ConfiguraciÃ³n |
|---------|----------------|---------------|
| **Redes Neuronales** | 82.78% | MLPClassifier: (5,6,7), SGD, identity, lr=constant |
| **Ãrboles de DecisiÃ³n** | **83.73%** âœ… | DecisionTreeClassifier: max_depth=4, gini |

### ğŸ’¡ Conclusiones Comparativas:

1. **Los Ã¡rboles de decisiÃ³n superan ligeramente** a las redes neuronales (+0.95%)

2. **Simplicidad vs Complejidad:**
   - Ãrboles: MÃ¡s simples, interpretables, entrenamiento rÃ¡pido
   - Redes neuronales: MÃ¡s complejas, requieren mÃ¡s ajuste de hiperparÃ¡metros

3. **Interpretabilidad:** Los Ã¡rboles permiten visualizar las reglas de decisiÃ³n

4. **Robustez:** Ambos criterios (gini/entropy) producen el mismo Ã¡rbol, indicando estabilidad

---

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### 1. **Clonar el repositorio**
```bash
git clone https://github.com/Juanes-xd/MachineLearning.git
cd MachineLearning/ActividadML
```

### 2. **Instalar dependencias**
```bash
pip install scikit-learn pandas numpy matplotlib jupyter
```

### 3. **Ejecutar el notebook**
```bash
jupyter notebook notebook1.ipynb
```

### 4. **Ejecutar todas las celdas**
En Jupyter: `Cell > Run All`

---

## ğŸ“Š Visualizaciones

El proyecto incluye grÃ¡ficos de barras comparando el **accuracy** de los 5 modelos:

```python
plt.figure(figsize=(10, 6))
plt.bar(modelos, accuracies)
plt.ylabel('Accuracy')
plt.title('ComparaciÃ³n de Modelos')
plt.ylim([0.6, 0.8])
plt.show()
```

---

## ğŸ” AnÃ¡lisis y Conclusiones Generales

### Hallazgos Principales:

#### ğŸ§  Redes Neuronales (Actividad 1):
1. **Efectividad comprobada** para clasificaciÃ³n, alcanzando 82.78% de accuracy
2. **Arquitecturas intermedias** (5,6,7) superan a las muy simples o muy complejas
3. **Learning rate es crÃ­tico:** `constant` mejora rendimiento, `invscaling` lo deteriora
4. **SGD puede superar a Adam** con configuraciÃ³n adecuada
5. **FunciÃ³n identity** fue sorpresivamente efectiva en este dataset

#### ğŸŒ³ Ãrboles de DecisiÃ³n (Actividad 2):
1. **Mejor rendimiento global:** 83.73% de accuracy
2. **Profundidad Ã³ptima:** max_depth=4 evita overfitting
3. **Equivalencia gini/entropy:** Ambos criterios producen resultados idÃ©nticos
4. **Simplicidad y eficiencia:** Menos hiperparÃ¡metros que ajustar
5. **Interpretabilidad superior:** Se pueden visualizar las reglas de decisiÃ³n

### ğŸ¯ ConclusiÃ³n Final:

Para este problema especÃ­fico de predicciÃ³n de aprobaciÃ³n:
- âœ… **Ãrboles de DecisiÃ³n** son la mejor opciÃ³n (mayor accuracy, mÃ¡s simples, interpretables)
- âœ… **Redes Neuronales** son competitivas pero requieren mayor esfuerzo de configuraciÃ³n
- âœ… Ambas tÃ©cnicas superan el **80% de accuracy**, demostrando que el problema es predecible

### Recomendaciones para Trabajo Futuro:

- Implementar **Grid Search** para exploraciÃ³n automÃ¡tica de hiperparÃ¡metros
- Agregar **validaciÃ³n cruzada** (k-fold) para resultados mÃ¡s robustos
- Incluir mÃ©tricas adicionales: **precision, recall, F1-score, ROC-AUC**
- Analizar **matriz de confusiÃ³n** para entender tipos de errores
- Probar **Random Forest** y **Gradient Boosting** para mejorar Ã¡rboles
- Implementar **ensemble methods** combinando mÃºltiples modelos
- Fijar **random_state** en todos los modelos para reproducibilidad
- Realizar **anÃ¡lisis de importancia de caracterÃ­sticas**

---

## ğŸ“š Referencias

- [DocumentaciÃ³n scikit-learn - MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)
- [Student Performance Dataset](https://archive.ics.uci.edu/ml/datasets/student+performance)

---

## ğŸ“„ Licencia

Este proyecto fue desarrollado con fines acadÃ©micos para el curso de Machine Learning.

---

## ğŸ“§ Contacto

Para consultas sobre este proyecto, contactar a cualquier miembro del equipo listado al inicio de este documento.

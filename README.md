#  Predicci√≥n de Aprobaci√≥n de Curso de Matem√°ticas mediante Redes Neuronales

## Equipo de Trabajo
- **Juan Esteban Ortiz** - 2410227-3743
- **Juan David Olaya** - 202410206-3743
- **Pablo Esteban Becerra** - 202243506-3743
- **Fernando Cardona Giraldo** - 202241381-3743
- **Sara Yineth Suarez Reyes** - 202241923-3743

---

##  Descripci√≥n del Proyecto

Este proyecto implementa modelos de **redes neuronales multicapa (MLP)** para predecir si un estudiante aprobar√° un curso de matem√°ticas bas√°ndose en sus caracter√≠sticas demogr√°ficas, familiares y h√°bitos de estudio.

### Objetivo
Desarrollar y comparar diferentes arquitecturas de redes neuronales para clasificar estudiantes en dos categor√≠as:
- **Aprueba** (approved = 1)
- **No aprueba** (approved = 0)

---

## Estructura del Proyecto

```
ActividadML/
‚îÇ
‚îú‚îÄ‚îÄ notebook1.ipynb                    # Actividad 1: Redes Neuronales
‚îú‚îÄ‚îÄ notebook2.ipynb                    # Actividad 2: √Årboles de Decisi√≥n
‚îú‚îÄ‚îÄ student_performance.csv            # Dataset de estudiantes
‚îú‚îÄ‚îÄ Informe Machine learning.pdf       # Informe completo del proyecto
‚îî‚îÄ‚îÄ README.md                          # Este archivo
```

---

## Dataset

**Archivo:** `student_performance.csv`

### Caracter√≠sticas del Dataset:
- **Total de registros:** 1,044 estudiantes
- **Atributos totales:** 17 variables
- **Variable objetivo:** `approved` (binaria: 0 o 1)

### Atributos Num√©ricos (9):
1. `age` - Edad del estudiante
2. `Medu` - Educaci√≥n de la madre (0-4)
3. `Fedu` - Educaci√≥n del padre (0-4)
4. `traveltime` - Tiempo de viaje al colegio
5. `studytime` - Tiempo de estudio semanal
6. `failures` - N√∫mero de materias reprobadas
7. `goout` - Frecuencia de salidas
8. `Walc` - Consumo de alcohol fin de semana
9. `health` - Estado de salud (1-5)

### Atributos Categ√≥ricos (7):
1. `sex` - Sexo (M/F)
2. `famsize` - Tama√±o de familia
3. `Pstatus` - Estado de convivencia de los padres
4. `Mjob` - Ocupaci√≥n de la madre
5. `Fjob` - Ocupaci√≥n del padre
6. `internet` - Acceso a internet (yes/no)
7. `romantic` - En relaci√≥n rom√°ntica (yes/no)

---

## Tecnolog√≠as y Librer√≠as

```python
- Python 3.x
- scikit-learn      # Modelos de ML y preprocesamiento
- pandas            # Manipulaci√≥n de datos
- numpy             # Operaciones num√©ricas
- matplotlib        # Visualizaci√≥n
```

---

## Pipeline de Preprocesamiento

### 1. **Pipeline para Atributos Num√©ricos**
```python
num_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),    # Imputaci√≥n de valores faltantes
    ("scaler", StandardScaler())                       # Normalizaci√≥n (Œº=0, œÉ=1)
])
```

### 2. **Pipeline para Atributos Categ√≥ricos**
```python
cat_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),  # Imputaci√≥n con moda
    ("cat_encoder", OneHotEncoder(sparse_output=False))     # Codificaci√≥n One-Hot
])
```

### 3. **Pipeline Completo**
```python
full_pipeline = ColumnTransformer([
    ("num", num_pipeline, num_attribs),
    ("cat", cat_pipeline, cat_attribs),
])
```

**Resultado:** 9 atributos num√©ricos + codificaci√≥n categ√≥rica ‚Üí matriz de caracter√≠sticas lista para entrenamiento

---

---

# ACTIVIDAD 1: Redes Neuronales (notebook1.ipynb)

## Modelos Implementados

Se entrenaron **5 modelos de redes neuronales** con diferentes configuraciones:

| Modelo | Funci√≥n Activaci√≥n | Solver | Arquitectura | Learning Rate |
|--------|-------------------|--------|--------------|---------------|
| **Modelo 1** | ReLU | LBFGS | (10, 5) | - |
| **Modelo 2** | Identity | SGD | (5, 6, 7) | constant |
| **Modelo 3** | Tanh | Adam | (8, 3, 2, 6) | - |
| **Modelo 4** | Logistic | Adam | (20,) | - |
| **Modelo 5** | ReLU | Adam | (3, 5, 7, 9, 10) | - |

### Par√°metros Comunes:
- **Divisi√≥n de datos:** 80% entrenamiento / 20% prueba
- **M√©trica de evaluaci√≥n:** Accuracy
- **Max iteraciones:** 1000

---

## Resultados

### Primera Ejecuci√≥n (sin learning_rate):
- **Mejor modelo:** Modelo 2
- **Accuracy:** 0.8182
- **Configuraci√≥n:** activation='identity', solver='sgd', hidden_layer_sizes=(5,6,7)

### Optimizaci√≥n con learning_rate:
| Configuraci√≥n | Accuracy | Observaci√≥n |
|--------------|----------|-------------|
| `learning_rate='constant'` | **0.8278** |  Mejor resultado |
| `learning_rate='adaptive'` | 0.8086 | Disminuci√≥n |
| `learning_rate='invscaling'` | 0.7273 | Peor resultado |

### Conclusi√≥n Actividad 1:
El **Modelo 2 con learning_rate='constant'** logr√≥ el mejor desempe√±o con **82.78% de accuracy**.

---

# ACTIVIDAD 2: √Årboles de Decisi√≥n (notebook2.ipynb)

## Descripci√≥n

Esta actividad aplica **√°rboles de decisi√≥n** al mismo dataset de estudiantes, comparando diferentes configuraciones de hiperpar√°metros para optimizar el rendimiento del clasificador.

## Objetivo

Determinar los hiperpar√°metros √≥ptimos para un √°rbol de decisi√≥n que prediga la aprobaci√≥n del curso de matem√°ticas, experimentando con:
- Diferentes profundidades del √°rbol (`max_depth`)
- Criterios de impureza (`gini` vs `entropy`)
- N√∫mero m√≠nimo de muestras para dividir (`min_samples_split`)

## Modelos de √Årboles de Decisi√≥n

### Experimento 1: Variaci√≥n de max_depth con criterio Gini

| Modelo | max_depth | Criterio | Accuracy |
|--------|-----------|----------|----------|
| Modelo 1 | 2 | gini | ~0.74 |
| Modelo 2 | 4 | gini | **0.8373** |
| Modelo 3 | 6 | gini | ~0.81 |
| Modelo 4 | 8 | gini | ~0.80 |
| Modelo 5 | 10 | gini | ~0.78 |

### Experimento 2: Variaci√≥n de max_depth con criterio Entropy

| Modelo | max_depth | Criterio | Accuracy |
|--------|-----------|----------|----------|
| Modelo 1 | 2 | entropy | ~0.74 |
| Modelo 2 | 4 | entropy | **0.8373** |
| Modelo 3 | 6 | entropy | ~0.81 |
| Modelo 4 | 8 | entropy | ~0.80 |
| Modelo 5 | 10 | entropy | ~0.78 |

### Observaci√≥n Importante:
Ambos criterios (`gini` y `entropy`) producen **resultados id√©nticos** con `max_depth=4`, logrando **83.73% de accuracy**. Esto indica que ambos m√©todos encuentran las mismas divisiones √≥ptimas en el √°rbol.

### Experimento 3: Variaci√≥n de min_samples_split

Con los mejores hiperpar√°metros (`max_depth=4`, `criterion='gini'`):

| min_samples_split | Accuracy |
|-------------------|----------|
| 2 | 0.8373 |
| 10 | 0.8373 |
| 20 | 0.8373 |

**Conclusi√≥n:** El par√°metro `min_samples_split` **no afecta** el accuracy cuando `max_depth=4`, ya que la profundidad m√°xima limita el crecimiento del √°rbol antes de que este par√°metro entre en acci√≥n.

## Configuraci√≥n √ìptima del √Årbol

```python
DecisionTreeClassifier(
    max_depth=4,
    criterion='gini',  # o 'entropy' (mismo resultado)
    min_samples_split=2
)
```

**Accuracy alcanzado:** **83.73%**

## üìä Comparaci√≥n: Redes Neuronales vs √Årboles de Decisi√≥n

| T√©cnica | Mejor Accuracy | Configuraci√≥n |
|---------|----------------|---------------|
| **Redes Neuronales** | 82.78% | MLPClassifier: (5,6,7), SGD, identity, lr=constant |
| **√Årboles de Decisi√≥n** | **83.73%** ‚úÖ | DecisionTreeClassifier: max_depth=4, gini |

###  Conclusiones Comparativas:

1. **Los √°rboles de decisi√≥n superan ligeramente** a las redes neuronales (+0.95%)

2. **Simplicidad vs Complejidad:**
   - √Årboles: M√°s simples, interpretables, entrenamiento r√°pido
   - Redes neuronales: M√°s complejas, requieren m√°s ajuste de hiperpar√°metros

3. **Interpretabilidad:** Los √°rboles permiten visualizar las reglas de decisi√≥n

4. **Robustez:** Ambos criterios (gini/entropy) producen el mismo √°rbol, indicando estabilidad

---

## C√≥mo Ejecutar el Proyecto

### 1. **Clonar el repositorio**
```bash
git clone https://github.com/Juanes-xd/MachineLearning.git
cd MachineLearning/ActividadML
```

### 2. **Instalar dependencias**
```bash
pip install scikit-learn pandas numpy matplotlib jupyter
```

### 3. **Ejecutar el notebook**
```bash
jupyter notebook notebook1.ipynb
```

### 4. **Ejecutar todas las celdas**
En Jupyter: `Cell > Run All`

---


##  Referencias

- [Documentaci√≥n scikit-learn - MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)
- [Student Performance Dataset](https://archive.ics.uci.edu/ml/datasets/student+performance)


